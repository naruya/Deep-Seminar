{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iE_4ClHK4uc9"
   },
   "source": [
    "# 分類・回帰（MLP・CNN）\n",
    "\n",
    "- ランタイム->ランタイムのタイプを変更->GPU\n",
    "- データのダウンロードに時間がかかるのでとりあえず実行してください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gi17XNnJKTYL"
   },
   "source": [
    "# 分類\n",
    "ref: https://github.com/pytorch/examples/blob/master/mnist/main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g7Id28jzL3es"
   },
   "source": [
    "- Negative Log-Ligelihood (NLL, 負の対数尤度)\n",
    "  - $\\mathbf{y}$を出力(各クラスの確率のようなベクトル)、$\\mathbf{t}$を正解のone_hotベクトルとしたとき、\n",
    "$$ \n",
    "Loss(\\mathbf{y}) = -\\log(y_i) \\quad (ただし y_i=t_i)\n",
    "$$\n",
    "\n",
    "  - ref: https://ljvmiranda921.github.io/notebook/2017/08/13/softmax-and-the-negative-log-likelihood/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "irqWQCaf4l-G"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000]\tLoss: 2.310584\n",
      "Train Epoch: 1 [6400/60000]\tLoss: 0.156014\n",
      "Train Epoch: 1 [12800/60000]\tLoss: 0.094682\n",
      "Train Epoch: 1 [19200/60000]\tLoss: 0.163271\n",
      "Train Epoch: 1 [25600/60000]\tLoss: 0.139334\n",
      "Train Epoch: 1 [32000/60000]\tLoss: 0.018503\n",
      "Train Epoch: 1 [38400/60000]\tLoss: 0.071137\n",
      "Train Epoch: 1 [44800/60000]\tLoss: 0.217014\n",
      "Train Epoch: 1 [51200/60000]\tLoss: 0.066358\n",
      "Train Epoch: 1 [57600/60000]\tLoss: 0.048868\n",
      "\n",
      "Test set: Average loss: 0.0471, Accuracy: 9827/10000 (98%)\n",
      "\n",
      "Train Epoch: 2 [0/60000]\tLoss: 0.133830\n",
      "Train Epoch: 2 [6400/60000]\tLoss: 0.093764\n",
      "Train Epoch: 2 [12800/60000]\tLoss: 0.067540\n",
      "Train Epoch: 2 [19200/60000]\tLoss: 0.046111\n",
      "Train Epoch: 2 [25600/60000]\tLoss: 0.058343\n",
      "Train Epoch: 2 [32000/60000]\tLoss: 0.065761\n",
      "Train Epoch: 2 [38400/60000]\tLoss: 0.051563\n",
      "Train Epoch: 2 [44800/60000]\tLoss: 0.014348\n",
      "Train Epoch: 2 [51200/60000]\tLoss: 0.018240\n",
      "Train Epoch: 2 [57600/60000]\tLoss: 0.043940\n",
      "\n",
      "Test set: Average loss: 0.0363, Accuracy: 9875/10000 (99%)\n",
      "\n",
      "Train Epoch: 3 [0/60000]\tLoss: 0.007083\n",
      "Train Epoch: 3 [6400/60000]\tLoss: 0.018801\n",
      "Train Epoch: 3 [12800/60000]\tLoss: 0.108532\n",
      "Train Epoch: 3 [19200/60000]\tLoss: 0.113845\n",
      "Train Epoch: 3 [25600/60000]\tLoss: 0.071622\n",
      "Train Epoch: 3 [32000/60000]\tLoss: 0.021003\n",
      "Train Epoch: 3 [38400/60000]\tLoss: 0.045345\n",
      "Train Epoch: 3 [44800/60000]\tLoss: 0.277034\n",
      "Train Epoch: 3 [51200/60000]\tLoss: 0.127195\n",
      "Train Epoch: 3 [57600/60000]\tLoss: 0.048126\n",
      "\n",
      "Test set: Average loss: 0.0326, Accuracy: 9891/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{}]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                loss.item()))\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "train_kwargs = {'batch_size': 64}\n",
    "test_kwargs = {'batch_size': 1000}\n",
    "\n",
    "cuda_kwargs = {'num_workers': 1,\n",
    "                'pin_memory': True,\n",
    "                'shuffle': True}\n",
    "train_kwargs.update(cuda_kwargs)\n",
    "test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    # transforms.Resize(56)  # 演習用\n",
    "    ])\n",
    "\n",
    "dataset1 = datasets.MNIST('../data', train=True, download=True,\n",
    "                    transform=transform)\n",
    "dataset2 = datasets.MNIST('../data', train=False,\n",
    "                    transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
    "\n",
    "model = Net().to(device)\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=1.0)\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n",
    "for epoch in range(1, 4):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)\n",
    "    scheduler.step()\n",
    "\n",
    "torch.save(model.state_dict(), \"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "q8ash6-6SUFa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x1296 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 可視化\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "N=5\n",
    "\n",
    "data, target = iter(test_loader).next()\n",
    "data = data[:5].to(device)\n",
    "print(data.shape)\n",
    "\n",
    "data_np = data.detach().cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(18,18))\n",
    "for i in range(N):\n",
    "  plt.subplot(1,N,i+1); plt.imshow(data_np[i].squeeze(), \"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BhA__d_xTqlN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 9, 7, 2], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# 予測結果の表示\n",
    "\n",
    "pred = torch.argmax(model(data[:N]), 1)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7i3AxxjQpX6"
   },
   "source": [
    "- 一通り確認出来たら、`transforms.Resize(56)  # 演習用` のコメントアウトを外して、新しい画像サイズで使えるようにモデルを修正してみましょう\n",
    "  - `Net`クラスの`forward`メソッド内で`print(x.shape)`などとして各層で出力される特徴マップや特徴ベクトルのサイズを確認していき、どこの層のパラメタ数を調整すればよいか考えるとうまく行きます。\n",
    "  - (一か所変えるだけでも動きます。)\n",
    "- Conv2Dを通した時に出力される特徴マップのサイズを計算してみるとより理解が深まると思います。\n",
    "  - ref: [PytorchのConv2Dの詳細](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sd_7Wml3KU89"
   },
   "source": [
    "# 回帰\n",
    "\n",
    "(余力がある人向け)\n",
    "\n",
    "ref: https://github.com/pytorch/examples/blob/master/regression/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "OYfgCcd_9FOm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.000339 after 332 batches\n",
      "==> Learned function:\ty = +7.08 x^1 -0.02 x^2 +4.09 x^3 +2.65 x^4 +2.69\n",
      "==> Actual function:\ty = +7.06 x^1 -0.06 x^2 +4.11 x^3 +2.66 x^4 +2.70\n"
     ]
    }
   ],
   "source": [
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "POLY_DEGREE = 4\n",
    "W_target = torch.randn(POLY_DEGREE, 1) * 5\n",
    "b_target = torch.randn(1) * 5\n",
    "\n",
    "\n",
    "def make_features(x):\n",
    "    \"\"\"Builds features i.e. a matrix with columns [x, x^2, x^3, x^4].\"\"\"\n",
    "    x = x.unsqueeze(1)\n",
    "    return torch.cat([x ** i for i in range(1, POLY_DEGREE+1)], 1)\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    \"\"\"Approximated function.\"\"\"\n",
    "    return x.mm(W_target) + b_target.item()\n",
    "\n",
    "\n",
    "def poly_desc(W, b):\n",
    "    \"\"\"Creates a string description of a polynomial.\"\"\"\n",
    "    result = 'y = '\n",
    "    for i, w in enumerate(W):\n",
    "        result += '{:+.2f} x^{} '.format(w, i + 1)\n",
    "    result += '{:+.2f}'.format(b[0])\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_batch(batch_size=32):\n",
    "    \"\"\"Builds a batch i.e. (x, f(x)) pair.\"\"\"\n",
    "    random = torch.randn(batch_size)\n",
    "    x = make_features(random)\n",
    "    y = f(x)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "# Define model\n",
    "fc = torch.nn.Linear(W_target.size(0), 1)\n",
    "\n",
    "for batch_idx in count(1):\n",
    "    # Get data\n",
    "    batch_x, batch_y = get_batch()\n",
    "\n",
    "    # Reset gradients\n",
    "    fc.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    output = F.smooth_l1_loss(fc(batch_x), batch_y)\n",
    "    loss = output.item()\n",
    "\n",
    "    # Backward pass\n",
    "    output.backward()\n",
    "\n",
    "    # Apply gradients\n",
    "    for param in fc.parameters():\n",
    "        param.data.add_(-0.1 * param.grad)\n",
    "\n",
    "    # Stop criterion\n",
    "    if loss < 1e-3:\n",
    "        break\n",
    "\n",
    "print('Loss: {:.6f} after {} batches'.format(loss, batch_idx))\n",
    "print('==> Learned function:\\t' + poly_desc(fc.weight.view(-1), fc.bias))\n",
    "print('==> Actual function:\\t' + poly_desc(W_target.view(-1), b_target))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNXanr1ZoSi5Y4nqFyurpfH",
   "collapsed_sections": [],
   "name": "exercise4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
